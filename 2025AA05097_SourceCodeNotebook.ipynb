{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14d9f86c",
      "metadata": {
        "id": "14d9f86c"
      },
      "source": [
        "# Dry Bean Dataset (Multi-Class) â€” 6 ML Models + Required Metrics\n",
        "\n",
        "This is the notebook with the whole source code to analyze the **Dry Bean Dataset** (multi-class, 7 classes) and implementing **all 6 required models** on the **same dataset**.\n",
        "\n",
        "## Required metrics (reported for every model)\n",
        "- **Accuracy**\n",
        "- **AUC (multi-class ROC-AUC, OvR macro)**\n",
        "- **Precision (macro)**\n",
        "- **Recall (macro)**\n",
        "- **F1-score (macro)**\n",
        "- **Matthews Correlation Coefficient (MCC)**\n",
        "\n",
        "## Models\n",
        "1. Logistic Regression (multinomial)\n",
        "2. Decision Tree\n",
        "3. KNN\n",
        "4. Naive Bayes (Gaussian)\n",
        "5. Random Forest\n",
        "6. XGBoost\n",
        "\n",
        "This notebook also:\n",
        "- saves trained models into `model/`\n",
        "- saves a `label_encoder` for consistent class handling\n",
        "- generates `app.py` (Streamlit), `requirements.txt`, and `README.md` for deployment in GITHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1QPVgE_wPPUo"
      },
      "id": "1QPVgE_wPPUo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb71e1b",
      "metadata": {
        "id": "4bb71e1b"
      },
      "outputs": [],
      "source": [
        "# Core\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Modeling\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503ef0cb",
      "metadata": {
        "id": "503ef0cb"
      },
      "source": [
        "## 1) Load dataset\n",
        "Here we set `DATA_PATH` as the locally saved Dry Bean CSV dataset file.\n",
        "\n",
        "- Features: numeric columns (16 features in the UCI dataset)\n",
        "- Target: class column (often named **Class**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08046ee9",
      "metadata": {
        "id": "08046ee9"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Dry_Bean_Dataset.xlsx\"\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find {DATA_PATH}. Set DATA_PATH correctly.\"\n",
        "    )\n",
        "\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "test_df = df.sample(300, random_state=42)\n",
        "test_df.to_csv(\"test_upload.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6ef196",
      "metadata": {
        "id": "ca6ef196"
      },
      "source": [
        "## 2) Identify target + encode classes\n",
        "\n",
        "We label-encode the target (bean type) to integers 0..(K-1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9849dcf",
      "metadata": {
        "id": "d9849dcf"
      },
      "outputs": [],
      "source": [
        "# Common target column name on Kaggle/UCI: 'Class'\n",
        "\n",
        "TARGET_COL = \"Class\" if \"Class\" in df.columns else df.columns[-1]\n",
        "\n",
        "X = df.drop(columns=[TARGET_COL]).copy()\n",
        "y_raw = df[TARGET_COL].copy()\n",
        "\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "if X.isna().any().any():\n",
        "    before = len(X)\n",
        "    mask = ~X.isna().any(axis=1)\n",
        "    X = X.loc[mask].reset_index(drop=True)\n",
        "    y_raw = y_raw.loc[mask].reset_index(drop=True)\n",
        "    print(f\"Dropped {before - len(X)} rows due to non-numeric/NaN features.\")\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "\n",
        "print(\"Target column:\", TARGET_COL)\n",
        "print(\"Num features:\", X.shape[1])\n",
        "print(\"Classes:\", list(le.classes_))\n",
        "print(\"Class distribution (counts):\")\n",
        "print(pd.Series(y).value_counts().sort_index().rename(index=lambda i: le.classes_[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797378b7",
      "metadata": {
        "id": "797378b7"
      },
      "source": [
        "## 3) Train/Test split for Data\n",
        "\n",
        "Stratified split preserves class proportions (same for all models)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48770069",
      "metadata": {
        "id": "48770069"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74024088",
      "metadata": {
        "id": "74024088"
      },
      "source": [
        "## 4) Defining (call) the 6 models\n",
        "\n",
        "Scaling is used for:\n",
        "- Logistic Regression\n",
        "- KNN\n",
        "\n",
        "Tree/ensemble models don't require scaling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158d6772",
      "metadata": {
        "id": "158d6772"
      },
      "outputs": [],
      "source": [
        "num_classes = len(le.classes_)\n",
        "\n",
        "models = {\n",
        "    #Scaled models below - LR and KNN\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", LogisticRegression(\n",
        "            max_iter=4000,\n",
        "            solver=\"lbfgs\",\n",
        "            multi_class=\"multinomial\",\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    \"KNN\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", KNeighborsClassifier(n_neighbors=9))\n",
        "    ]),\n",
        "    #Non scaled models - DT, RF, XGBoost, and NBClassifiers\n",
        "    \"Decision Tree\": DecisionTreeClassifier(\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Naive Bayes (Gaussian)\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=150,\n",
        "        max_depth=15,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=num_classes,\n",
        "        n_estimators=600,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=42,\n",
        "        eval_metric=\"mlogloss\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "list(models.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48db4097",
      "metadata": {
        "id": "48db4097"
      },
      "source": [
        "## 5) Evaluation functions (multi-class required metrics)\n",
        "\n",
        "- **Precision/Recall/F1** are reported as **macro-average**\n",
        "- **AUC** is computed as **multi-class ROC-AUC** using **OvR** with **macro averaging**\n",
        "- **MCC** supports multi-class directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61373a2c",
      "metadata": {
        "id": "61373a2c"
      },
      "outputs": [],
      "source": [
        "def get_score_matrix(model, X):\n",
        "    \"\"\"Return probability matrix for multi-class ROC-AUC, if available.\"\"\"\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        return model.predict_proba(X)\n",
        "    return None\n",
        "\n",
        "def evaluate_model(name, model, X_test, y_test, class_names):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_score = get_score_matrix(model, X_test)\n",
        "\n",
        "    metrics = {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision_macro\": precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"Recall_macro\": recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"F1_macro\": f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred),\n",
        "    }\n",
        "\n",
        "    if y_score is not None and y_score.ndim == 2 and y_score.shape[1] == len(class_names):\n",
        "        metrics[\"AUC_ovr_macro\"] = roc_auc_score(\n",
        "            y_test, y_score,\n",
        "            multi_class=\"ovr\",\n",
        "            average=\"macro\"\n",
        "        )\n",
        "    else:\n",
        "        metrics[\"AUC_ovr_macro\"] = np.nan\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=class_names, digits=4, zero_division=0)\n",
        "    return metrics, cm, report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14558217",
      "metadata": {
        "id": "14558217"
      },
      "source": [
        "## 6) Training & evaluating all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a6812e",
      "metadata": {
        "id": "a4a6812e"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "conf_mats = {}\n",
        "reports = {}\n",
        "fitted_models = {}\n",
        "\n",
        "class_names = list(le.classes_)\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    fitted_models[name] = model\n",
        "\n",
        "    met, cm, rep = evaluate_model(name, model, X_test, y_test, class_names)\n",
        "    results.append(met)\n",
        "    conf_mats[name] = cm\n",
        "    reports[name] = rep\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"F1_macro\", ascending=False)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b6036d",
      "metadata": {
        "id": "e7b6036d"
      },
      "source": [
        "## 7) Processed Model Report to identify best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fdf77e5",
      "metadata": {
        "id": "7fdf77e5"
      },
      "outputs": [],
      "source": [
        "best_model_name = results_df.iloc[0][\"Model\"]\n",
        "print(\"Best model (by F1_macro):\", best_model_name)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(reports[best_model_name])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2da63fa",
      "metadata": {
        "id": "b2da63fa"
      },
      "source": [
        "## 8) Confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a750c9",
      "metadata": {
        "id": "56a750c9"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, title=\"Confusion Matrix\"):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=45, ha=\"right\")\n",
        "    plt.yticks(tick_marks, labels)\n",
        "\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], \"d\"),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "for name, cm in conf_mats.items():\n",
        "    plot_confusion_matrix(cm, class_names, title=f\"{name} - Confusion Matrix\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7f128e",
      "metadata": {
        "id": "da7f128e"
      },
      "source": [
        "## 9) 5-fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d622ccb",
      "metadata": {
        "id": "1d622ccb"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_rows = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"f1_macro\")\n",
        "    cv_rows.append({\n",
        "        \"Model\": name,\n",
        "        \"CV_F1_macro_Mean\": scores.mean(),\n",
        "        \"CV_F1_macro_Std\": scores.std()\n",
        "    })\n",
        "\n",
        "cv_df = pd.DataFrame(cv_rows).sort_values(by=\"CV_F1_macro_Mean\", ascending=False)\n",
        "cv_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b04c815",
      "metadata": {
        "id": "8b04c815"
      },
      "source": [
        "## 10) Saving the models (with the label encoders for Streamlit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1309a53",
      "metadata": {
        "id": "f1309a53"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"model\", exist_ok=True)\n",
        "\n",
        "joblib.dump(le, \"model/label_encoder.joblib\")\n",
        "\n",
        "for name, model in fitted_models.items():\n",
        "    safe_name = name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
        "    joblib.dump(model, f\"model/{safe_name}.joblib\")\n",
        "\n",
        "results_df_out = results_df.copy()\n",
        "results_df_out.to_csv(\"model/model_comparison_metrics.csv\", index=False)\n",
        "with open(\"model/model_comparison_metrics.json\", \"w\") as f:\n",
        "    json.dump(results_df_out.to_dict(orient=\"records\"), f, indent=2)\n",
        "\n",
        "print(\"Saved files in model/:\")\n",
        "print(os.listdir(\"model\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7e959d",
      "metadata": {
        "id": "0d7e959d"
      },
      "source": [
        "## 11) Generating Requirements for the GITHub and Streamlink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d531ab",
      "metadata": {
        "id": "80d531ab"
      },
      "outputs": [],
      "source": [
        "APP_CODE = '''\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "\n",
        "st.set_page_config(page_title=\"Dry Bean Classifier\", layout=\"wide\")\n",
        "st.title(\"Dry Bean Classification (6 Models)\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "Upload a CSV with the same **feature columns** used for training, plus a target column (bean class).\n",
        "If your target column is named `Class`, the app will use it automatically; otherwise it will use the **last column**.\n",
        "\"\"\")\n",
        "\n",
        "uploaded = st.file_uploader(\"Upload CSV\", type=[\"csv\"])\n",
        "\n",
        "MODEL_DIR = \"model\"\n",
        "ENCODER_PATH = os.path.join(MODEL_DIR, \"label_encoder.joblib\")\n",
        "\n",
        "model_files = {\n",
        "    \"Logistic Regression\": \"logistic_regression.joblib\",\n",
        "    \"Decision Tree\": \"decision_tree.joblib\",\n",
        "    \"KNN\": \"knn.joblib\",\n",
        "    \"Naive Bayes (Gaussian)\": \"naive_bayes_gaussian.joblib\",\n",
        "    \"Random Forest\": \"random_forest.joblib\",\n",
        "    \"XGBoost\": \"xgboost.joblib\"\n",
        "}\n",
        "\n",
        "def compute_metrics_multiclass(y_true, y_pred, y_proba, n_classes):\n",
        "    out = {\n",
        "        \"Accuracy\": float(accuracy_score(y_true, y_pred)),\n",
        "        \"Precision_macro\": float(precision_score(y_true, y_pred, average=\"macro\", zero_division=0)),\n",
        "        \"Recall_macro\": float(recall_score(y_true, y_pred, average=\"macro\", zero_division=0)),\n",
        "        \"F1_macro\": float(f1_score(y_true, y_pred, average=\"macro\", zero_division=0)),\n",
        "        \"MCC\": float(matthews_corrcoef(y_true, y_pred)),\n",
        "    }\n",
        "    if y_proba is not None and y_proba.ndim == 2 and y_proba.shape[1] == n_classes:\n",
        "        out[\"AUC_ovr_macro\"] = float(roc_auc_score(y_true, y_proba, multi_class=\"ovr\", average=\"macro\"))\n",
        "    else:\n",
        "        out[\"AUC_ovr_macro\"] = None\n",
        "    return out\n",
        "\n",
        "col1, col2 = st.columns([1, 2])\n",
        "\n",
        "with col1:\n",
        "    selected = st.selectbox(\"Select Model\", list(model_files.keys()))\n",
        "\n",
        "if uploaded is not None:\n",
        "    df = pd.read_csv(uploaded)\n",
        "\n",
        "    target_col = \"Class\" if \"Class\" in df.columns else df.columns[-1]\n",
        "    X = df.drop(columns=[target_col]).copy()\n",
        "    y_raw = df[target_col].copy()\n",
        "\n",
        "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    if X.isna().any().any():\n",
        "        st.warning(\"Some feature values could not be parsed as numeric. Dropping rows with NaNs.\")\n",
        "        mask = ~X.isna().any(axis=1)\n",
        "        X = X.loc[mask].reset_index(drop=True)\n",
        "        y_raw = y_raw.loc[mask].reset_index(drop=True)\n",
        "\n",
        "    if not os.path.exists(ENCODER_PATH):\n",
        "        st.error(\"label_encoder.joblib not found in model/. Please include it in your repo.\")\n",
        "        st.stop()\n",
        "\n",
        "    le = joblib.load(ENCODER_PATH)\n",
        "    class_names = list(le.classes_)\n",
        "    n_classes = len(class_names)\n",
        "\n",
        "    try:\n",
        "        y = le.transform(y_raw)\n",
        "    except Exception:\n",
        "        y = pd.to_numeric(y_raw, errors=\"coerce\").astype(int).to_numpy()\n",
        "\n",
        "    model_path = os.path.join(MODEL_DIR, model_files[selected])\n",
        "    if not os.path.exists(model_path):\n",
        "        st.error(f\"Model file not found: {model_path}. Ensure model/ folder is in your repo.\")\n",
        "        st.stop()\n",
        "\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "    y_proba = model.predict_proba(X) if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "    metrics = compute_metrics_multiclass(y, y_pred, y_proba, n_classes)\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Evaluation Metrics\")\n",
        "        st.json(metrics)\n",
        "\n",
        "        st.subheader(\"Confusion Matrix\")\n",
        "        st.write(cm)\n",
        "\n",
        "        st.subheader(\"Classification Report\")\n",
        "        st.text(classification_report(y, y_pred, target_names=class_names, digits=4, zero_division=0))\n",
        "else:\n",
        "    st.info(\"Upload a CSV to evaluate the selected model.\")\n",
        "'''\n",
        "\n",
        "REQS = \"\"\"pandas\n",
        "numpy\n",
        "scikit-learn\n",
        "xgboost\n",
        "joblib\n",
        "matplotlib\n",
        "streamlit\n",
        "\"\"\"\n",
        "\n",
        "README = \"\"\"# Dry Bean Classification (6 Models)\n",
        "\n",
        "## Problem Statement\n",
        "The objective of this project is to classify dry beans into one of seven categories\n",
        "based on geometric and morphological features using supervised machine learning techniques.\n",
        "\n",
        "## Dataset\n",
        "Dry Bean Dataset (public repository).\n",
        "- Instances: 13,611\n",
        "- Features: 16 numerical attributes\n",
        "- Classes: 7 bean types (BARBUNYA, BOMBAY, CALI, DERMASON, HOROZ, SEKER, SIRA)\n",
        "\n",
        "## Models Implemented\n",
        "1. Logistic Regression (Multinomial)\n",
        "2. Decision Tree\n",
        "3. K-Nearest Neighbors (KNN)\n",
        "4. Gaussian Naive Bayes\n",
        "5. Random Forest\n",
        "6. XGBoost\n",
        "\n",
        "## Evaluation Metrics\n",
        "- Accuracy\n",
        "- AUC (multi-class ROC-AUC, OvR macro)\n",
        "- Precision (macro)\n",
        "- Recall (macro)\n",
        "- F1-score (macro)\n",
        "- MCC (Matthews Correlation Coefficient)\n",
        "\n",
        "## Deployment:\n",
        "The application is deployed using Streamlit Community Cloud and allows users to:\n",
        "- Upload a CSV dataset\n",
        "- Select one of six ML models\n",
        "- View evaluation metrics\n",
        "- View confusion matrix\n",
        "- Download predictions (if labels are not provided)\n",
        "\n",
        "## Run locally\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "Observations:\n",
        "XGBoost achieved the highest macro F1-score and overall accuracy, demonstrating\n",
        "superior performance in handling multi-class classification tasks.\n",
        "ML Model Name\tAccuracy\tPrecision\tRecall\tF1\tMCC\tAUC\n",
        "Logistic Regression\t0.921410\t0.935383\t0.932149\t0.933538\t0.905045\t0.994776\n",
        "Decision Tree\t0.892031\t0.907513\t0.909028\t0.908061\t0.869569\t0.944996\n",
        "kNN\t0.916269\t0.931763\t0.926738\t0.928868\t0.898792\t0.986807\n",
        "Naives-Bayes\t0.763863\t0.774427\t0.769417\t0.767750\t0.715406\t0.967193\n",
        "Random Forest\t0.920308\t0.934654\t0.930010\t0.932210\t0.903591\t0.993567\n",
        "XGBoost\t0.925450\t0.939923\t0.935143\t0.937430\t0.909807\t0.995291\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Observations:\n",
        "ML Model Name\tObservation on Model Performance and Output\n",
        "Logistic Regression\tAs a linear classifier with multinomial optimization, Logistic Regression achieved strong macro-averaged metrics, indicating effective separation of classes in feature space. However, its performance slightly declined for structurally similar beans, highlighting limitations in modelling nonlinear feature interactions.\n",
        "Decision Tree\tThe Decision Tree captured nonlinear decision boundaries but exhibited higher variance compared to ensemble methods. While it performed reasonably well, slight inconsistencies across classes suggest sensitivity to training data splits and potential overfitting.\n",
        "kNN\tkNN demonstrated competitive macro F1 performance by leveraging distance-based classification. However, its effectiveness depended heavily on feature scaling and class density, and performance degraded slightly in regions with overlapping morphological features.\n",
        "Naive Bayes\tGaussian Naive Bayes produced moderate results due to its strong independence assumption among features. Since geometric attributes in the dataset are correlated, this assumption reduced its ability to model complex class boundaries accurately.\n",
        "Random Forest (Ensemble)\tRandom Forest improved predictive stability by aggregating multiple decision trees, significantly reducing variance and improving macro-level metrics. It handled nonlinear relationships effectively and showed better class balance compared to single-tree models.\n",
        "XGBoost (Ensemble)\tXGBoost achieved the highest macro F1-score and overall accuracy due to its gradient boosting framework, which sequentially corrected previous errors. Its regularization and optimized tree-building strategy allowed superior handling of subtle inter-class differences, especially among morphologically overlapping bean types.\n",
        "\n",
        "\n",
        "## Notes\n",
        "- The app expects a CSV containing the same feature columns plus a target column named `Class` (preferred) or as the last column.\n",
        "- Trained models and label encoder are stored in the `model/` folder.\n",
        "\n",
        "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(APP_CODE)\n",
        "\n",
        "with open(\"requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(REQS)\n",
        "\n",
        "with open(\"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(README)\n",
        "\n",
        "print(\"Generated: app.py, requirements.txt, README.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a920b16a",
      "metadata": {
        "id": "a920b16a"
      },
      "source": [
        "## 12) FINAL RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7ca3fc",
      "metadata": {
        "id": "ca7ca3fc"
      },
      "outputs": [],
      "source": [
        "print(\"=== Model Comparison (Test Set) ===\")\n",
        "display(results_df.reset_index(drop=True))\n",
        "\n",
        "print(\"\\n=== Cross-Validation Summary (Train Set) ===\")\n",
        "display(cv_df.reset_index(drop=True))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}